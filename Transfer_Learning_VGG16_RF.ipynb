{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, svm, metrics\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "original_Coviddataset_dir = '../CT_COVID_DATA/'\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "train_covid_dir = \"C:/Users/siva7/Desktop/Covid-19/Chapter/content/SVM/train/covid/\"\n",
    "train_noncovid_dir = \"C:/Users/siva7/Desktop/Covid-19/Chapter/content/SVM/train/noncovid/\"\n",
    "validation_covid_dir = \"C:/Users/siva7/Desktop/Covid-19/Chapter/content/SVM/validation/covid/\"\n",
    "validation_noncovid_dir = \"C:/Users/siva7/Desktop/Covid-19/Chapter/content/SVM/validation/noncovid/\"\n",
    "test_covid_dir = \"C:/Users/siva7/Desktop/Covid-19/Chapter/content/SVM/test/covid/\"\n",
    "test_noncovid_dir = \"C:/Users/siva7/Desktop/Covid-19/Chapter/content/SVM/test/noncovid/\"\n",
    "\n",
    "print('total training cat images:', len(os.listdir(train_covid_dir)))\n",
    "print('total training dog images:', len(os.listdir(train_noncovid_dir)))\n",
    "print('total validation cat images:', len(os.listdir(validation_covid_dir)))\n",
    "print('total validation dog images:', len(os.listdir(validation_noncovid_dir)))\n",
    "print('total test cat images:', len(os.listdir(test_covid_dir)))\n",
    "print('total test dog images:', len(os.listdir(test_noncovid_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate convolutional base\n",
    "from keras.applications import VGG16\n",
    "\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "conv_base = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check architecture\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"../train/\"\n",
    "validation_dir =\"../validation/\"\n",
    "test_dir =\"../test/\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os, shutil\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 20\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, 7, 7, 512))\n",
    "    labels = np.zeros(shape=(sample_count))\n",
    "\n",
    "    generator = ImageDataGenerator(rescale=1./255).flow_from_directory(directory, \n",
    "    target_size=(img_width,img_height), batch_size = batch_size, class_mode='binary')\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    print('Entering for loop...');\n",
    "\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * 20 : (i + 1) * 20] = features_batch\n",
    "        labels[i * 20 : (i + 1) * 20] = labels_batch\n",
    "        i += 1\n",
    "        print(i);\n",
    "    \n",
    "        if (i * 20) >= sample_count:\n",
    "            break\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "train_features, train_labels = extract_features(train_dir, 200)  \n",
    "validation_features, validation_labels = extract_features(validation_dir, 100)\n",
    "test_features, test_labels = extract_features(test_dir, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_features)\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate training and validation sets\n",
    "rf_features = np.concatenate((train_features, validation_features))\n",
    "rf_labels = np.concatenate((train_labels, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import learning_curve,GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "X_train, y_train = rf_features.reshape(300,7*7*512), rf_labels\n",
    "\n",
    "rfc=RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [200, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "CV_rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc1=RandomForestClassifier(random_state=42, max_features='log2', n_estimators= 200, max_depth=8, criterion='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curves\n",
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator = rfc1,\n",
    "                                                        X = X_train,\n",
    "                                                        y = y_train,\n",
    "                                                        train_sizes = np.linspace(0.1,1.0,10),\n",
    "                                                        cv = 10)\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5,\n",
    "         label='Training accuracy')\n",
    "\n",
    "plt.fill_between(train_sizes,\n",
    "                 train_mean + train_std,\n",
    "                 train_mean - train_std,\n",
    "                 alpha=0.15, color='blue')\n",
    "\n",
    "\n",
    "plt.plot(train_sizes, test_mean, color='green', linestyle='--',\n",
    "         marker='s', markersize=5, label='Validation accuracy')\n",
    "plt.fill_between(train_sizes,\n",
    "                 test_mean + test_std,\n",
    "                 test_mean - test_std,\n",
    "                 alpha=0.15, color='green')\n",
    "plt.grid()\n",
    "plt.xlabel('Number of training samples')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim([0.5, 1.1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate training and validation sets\n",
    "svm_features = np.concatenate((train_features, validation_features,test_features))\n",
    "svm_labels = np.concatenate((train_labels, validation_labels,test_labels))\n",
    "\n",
    "X_train, y_train = svm_features.reshape(400,7*7*512), svm_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "print(\"\\nAccuracy score (mean) :\")\n",
    "acc=cross_val_score(rfc1, X_train, y_train, cv=10)\n",
    "\n",
    "print(acc)\n",
    "\n",
    "print(np.mean(acc))\n",
    "\n",
    "print(\"\\nAccuracy score (standard deviation):\")\n",
    "print(np.std(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_mean))\n",
    "print(len(test_mean))\n",
    "print(train_mean)\n",
    "print(test_mean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
